Abstract
主要问题：缺少 ground-truth 数据集，因此现有的方法都是无监督学习
To light up supervised learning approaches
To compare their performances with unsupervised learning-based methods
-> introduce a large-scale human-labeled <UR, Code> ground truth dataset, including the annotation process and statistic analysis


Introduction

Related Work

Review2Code System
- Unsupervised Systems
	- URR: classifies UR into predefined categories and defines a set of structure categories for source code files
	- ChangeAdvisor: clusters UR by HDP; measures the similarity between source code snippets and clusters with cosine similarity
	- ReviewSolver: utilizes a parse tree to capture the semantic information of UR and creates APG of the app; measures the similarity between phrases from the tree adn components from the graph
	- Where2Change: similar to ChangeAdvisor in clustering and similarity calculation; however, before similarity calculation, it additionally measures the similarity between UR clusters and issue reports
	- RISING: mainly composed of 2 steps: clustering and similarity calculation which is similar to above methods; in addition, it exploits commit messages as a medium to fill the lexicon gap between UR and source code snippets and uses a heuristic-based method to infer parameter k in K-means
- Supervised Candidates
	- UNIF: supervised extension of the NCS technique, which uses word embedding matrices to learn the mapping from tokens into vectors
	- CAT: an extension of CT, which can capture the structural characterisitics of the code
	- CodeBert: the first bimodal pre-trained model for multiple programming languages and natural languages
	- GraphCodeBert: leverages the semantic structure of code to learn code representation
- Selected Systems

Dataset Construction
	Data Collecting
	Preparation
	Annotating
	Statistical Analysis

Experimental Setups
	Settings
	Evaluation Metrics
	Research Questions

Discussion By Answering RQs

Threats to Validity

Conclusion and Future Work

