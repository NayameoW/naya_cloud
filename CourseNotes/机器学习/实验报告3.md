# 1 数据预处理
首先预览一下数据集：
![image.png](https://s2.loli.net/2023/04/03/FWyAwdOCDqzbTrH.png)

![image.png](https://s2.loli.net/2023/04/03/6GlsSP4Xa7JA1W3.png)

condition 中存在 null 数据，因此在处理时要将这些清洗掉：
![image.png](https://s2.loli.net/2023/04/03/iwBZnJt32LdWIlH.png)


考虑到数据集中有很多文本信息，而决策树算法的应用依赖于具体数值，所以要进行一定的处理。
![image.png](https://s2.loli.net/2023/04/03/TBHbSp2IskvRY5G.png)
![image.png](https://s2.loli.net/2023/04/03/2qXVKUaIPhpNMRS.png)
药品名称相对于样本总量来说也是一个不小的数目，因此无论是对齐进行怎么样的编码，都可能导致过拟合的结果。因此考虑直接将其删去。condition 先考虑将其留下，但是由于其数量也比较大，初步使用 ordinal 方式进行编码。最后还是发现不考虑 condition 正确率高。
而评论本来想将其转换成情感分数，但是效果并不好，并且有很多文本无法分析出合适的情感得分，故放弃。

# 2 决策树构建
## 2.1 叶子节点
![image.png](https://s2.loli.net/2023/04/03/47iurPc8O132baz.png)

## 2.2 树的构建
核心方法是递归构建决策树，具体代码过长且已加入注释故不展示：
#### 算法过程
1.  将所有的特征看成一个一个的节点。创建根节点。
2.  遍历所有特征。遍历到其中某一个特征时，遍历当前特征的所有分割方式，找到最好的分割点，将数据划分为不同的子节点，计算划分后子节点的信息熵。
3.  在遍历的所有特征中，比较寻找最优的特征以及最优特征的最优划分方式。选择信息增益最高的特征，根据特征则对当前数据集进行分割操作，产生子树。
4.  对新的子节点继续执行2 - 3步，直到下面的停止条件退出循环。

## 2.3 训练模型

![image.png](https://s2.loli.net/2023/04/03/r8uTediN2LaCbXz.png)

# 3 结果
最终预测结果如下：
![Snipaste_2023-04-03_16-19-54.png](https://s2.loli.net/2023/04/03/MV31JRPxkOuG58e.png)

对未完成的测试集进行预测：
![image.png](https://s2.loli.net/2023/04/03/SYN8snumfKyCzt5.png)
