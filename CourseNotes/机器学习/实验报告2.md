## 1 运行过程
### 1.1 加载数据集
由于 pytorch 自带 MNIST 数据集，因此直接调用 datasets 获取
![image.png](https://s2.loli.net/2023/03/23/yWKhFjrPTzYldeg.png)

![image.png](https://s2.loli.net/2023/03/23/XSrMpmKnR1Nsca9.png)

### 1.2 构建神经网络
这段代码实现了一个简单的CNN网络结构。其中包含两个卷积层和一个全连接层，并且在每个卷积之后都有ReLU激活函数和最大池化操作。输入数据为灰度图片，在经过两次不同参数设置的卷积核处理之后通过flatten操作将其转换成一维张量，再送入全连接神经网络进行分类任务。

![image.png](https://s2.loli.net/2023/03/23/cwuDKaXdBJnNorQ.png)


## 1.3 训练
使用了 PyTorch 提供的自动求导机制来计算梯度，并利用优化器（optimizer）来更新网络参数。在每个 epoch 内，我们遍历所有批次 (batch)，将输入张量 b_x 和标签 b_y 都转换为可求导变量 (Variable)，然后通过调用 cnn (b_x)[0]方法实现前向传播计算得到预测结果 output。接着根据预测结果和真实标签之间差异大小来计算损失 loss，并清空优化器中保存的历史累积梯度信息 。然后反向传播并执行优化步骤以更新神经网络权重及偏置参数，在此过程中会自动地计算出各层权重相应方向上需要移动多大距离 (即学习率\*gradient)，从而使得当前样本能够更好地拟合目标函数。
![image.png](https://s2.loli.net/2023/03/23/OB4HQjgXrzS9JCd.png)

![image.png](https://s2.loli.net/2023/03/23/5xRKoU17CDqwF3c.png)


## 2 结果展示

![image.png](https://s2.loli.net/2023/03/23/5KMTCeDQHqaoE4j.png)

